{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9902cd85",
   "metadata": {},
   "source": [
    "# Data Cleaning: Online Retail Dataset\n",
    "\n",
    "This notebook covers the first two phases of the data science workflow: loading and cleaning the raw data. Each step is explained in detail with comments. The final cleaned dataset will be saved as a new CSV file in the 'cleaned' folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd6951c",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "This step imports pandas, which is essential for data manipulation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5fef62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for data manipulation\n",
    "import pandas as pd  # pandas is the main library for handling tabular data in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76557f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pandas successfully imported!\n",
      "✅ Pandas version: 2.3.1\n",
      "✅ Pandas is accessible as 'pd'\n"
     ]
    }
   ],
   "source": [
    "# Verify pandas is imported and working\n",
    "print(f\"✅ Pandas successfully imported!\")\n",
    "print(f\"✅ Pandas version: {pd.__version__}\")\n",
    "print(f\"✅ Pandas is accessible as 'pd'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daebbc22",
   "metadata": {},
   "source": [
    "## 2. Load Raw Data\n",
    "Read the raw CSV file into a pandas DataFrame for further analysis and cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7778bfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of raw_df: <class 'pandas.core.frame.DataFrame'>\n",
      "Successfully loaded 1,067,371 rows and 8 columns\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset for cleaning\n",
    "# Read the raw CSV file into a pandas DataFrame\n",
    "# The CSV file is in the parent directory, so we need to go up one level\n",
    "raw_df = pd.read_csv('../online_retail.csv')  # Load the data from the CSV file\n",
    "print(\"Type of raw_df:\", type(raw_df))\n",
    "print(f\"Successfully loaded {len(raw_df):,} rows and {len(raw_df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e5f72e",
   "metadata": {},
   "source": [
    "## 3. Explore Data Structure\n",
    "Display the first few rows and info to understand the data types, columns, and structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d05f259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Invoice StockCode                          Description  Quantity  \\\n",
      "0  489434     85048  15CM CHRISTMAS GLASS BALL 20 LIGHTS        12   \n",
      "1  489434    79323P                   PINK CHERRY LIGHTS        12   \n",
      "2  489434    79323W                  WHITE CHERRY LIGHTS        12   \n",
      "3  489434     22041         RECORD FRAME 7\" SINGLE SIZE         48   \n",
      "4  489434     21232       STRAWBERRY CERAMIC TRINKET BOX        24   \n",
      "\n",
      "           InvoiceDate  Price  Customer ID         Country  \n",
      "0  2009-12-01 07:45:00   6.95      13085.0  United Kingdom  \n",
      "1  2009-12-01 07:45:00   6.75      13085.0  United Kingdom  \n",
      "2  2009-12-01 07:45:00   6.75      13085.0  United Kingdom  \n",
      "3  2009-12-01 07:45:00   2.10      13085.0  United Kingdom  \n",
      "4  2009-12-01 07:45:00   1.25      13085.0  United Kingdom  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1067371 entries, 0 to 1067370\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count    Dtype  \n",
      "---  ------       --------------    -----  \n",
      " 0   Invoice      1067371 non-null  object \n",
      " 1   StockCode    1067371 non-null  object \n",
      " 2   Description  1062989 non-null  object \n",
      " 3   Quantity     1067371 non-null  int64  \n",
      " 4   InvoiceDate  1067371 non-null  object \n",
      " 5   Price        1067371 non-null  float64\n",
      " 6   Customer ID  824364 non-null   float64\n",
      " 7   Country      1067371 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 65.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check the data format and columns\n",
    "print(raw_df.head())  # Show the first 5 rows to get a quick look at the data\n",
    "print(raw_df.info())  # Display column names, data types, and non-null counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854316de",
   "metadata": {},
   "source": [
    "## 4. Initial Data Inspection\n",
    "Summarize statistics and inspect for missing values and outliers to identify data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea6648ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Quantity         Price    Customer ID\n",
      "count  1.067371e+06  1.067371e+06  824364.000000\n",
      "mean   9.938898e+00  4.649388e+00   15324.638504\n",
      "std    1.727058e+02  1.235531e+02    1697.464450\n",
      "min   -8.099500e+04 -5.359436e+04   12346.000000\n",
      "25%    1.000000e+00  1.250000e+00   13975.000000\n",
      "50%    3.000000e+00  2.100000e+00   15255.000000\n",
      "75%    1.000000e+01  4.150000e+00   16797.000000\n",
      "max    8.099500e+04  3.897000e+04   18287.000000\n",
      "Invoice             0\n",
      "StockCode           0\n",
      "Description      4382\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "Price               0\n",
      "Customer ID    243007\n",
      "Country             0\n",
      "dtype: int64\n",
      "Value counts for Invoice:\n",
      "Invoice\n",
      "537434    1350\n",
      "538071    1304\n",
      "537638    1202\n",
      "537237    1194\n",
      "536876    1186\n",
      "Name: count, dtype: int64\n",
      "Value counts for StockCode:\n",
      "StockCode\n",
      "85123A    5829\n",
      "22423     4424\n",
      "85099B    4216\n",
      "21212     3318\n",
      "20725     3259\n",
      "Name: count, dtype: int64\n",
      "Value counts for Description:\n",
      "Description\n",
      "WHITE HANGING HEART T-LIGHT HOLDER    5918\n",
      "REGENCY CAKESTAND 3 TIER              4412\n",
      "NaN                                   4382\n",
      "JUMBO BAG RED RETROSPOT               3469\n",
      "ASSORTED COLOUR BIRD ORNAMENT         2958\n",
      "Name: count, dtype: int64\n",
      "Value counts for Quantity:\n",
      "Quantity\n",
      "1     294346\n",
      "2     159960\n",
      "12    121745\n",
      "6      85299\n",
      "3      72638\n",
      "Name: count, dtype: int64\n",
      "Value counts for InvoiceDate:\n",
      "InvoiceDate\n",
      "2010-12-06 16:57:00    1350\n",
      "2010-12-09 14:09:00    1304\n",
      "2010-12-07 15:28:00    1202\n",
      "2010-12-06 09:58:00    1194\n",
      "2010-12-03 11:36:00    1186\n",
      "Name: count, dtype: int64\n",
      "Value counts for Price:\n",
      "Price\n",
      "1.25    104428\n",
      "1.65     73808\n",
      "0.85     69218\n",
      "2.95     65862\n",
      "0.42     45438\n",
      "Name: count, dtype: int64\n",
      "Value counts for Customer ID:\n",
      "Customer ID\n",
      "NaN        243007\n",
      "17841.0     13097\n",
      "14911.0     11613\n",
      "12748.0      7307\n",
      "14606.0      6709\n",
      "Name: count, dtype: int64\n",
      "Value counts for Country:\n",
      "Country\n",
      "United Kingdom    981330\n",
      "EIRE               17866\n",
      "Germany            17624\n",
      "France             14330\n",
      "Netherlands         5140\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Summarize and inspect missing data\n",
    "print(raw_df.describe())  # Get summary statistics for numeric columns\n",
    "print(raw_df.isnull().sum())  # Count missing values in each column\n",
    "# Optionally, check value counts for key columns to spot outliers or unexpected values\n",
    "for col in raw_df.columns:\n",
    "    print(f\"Value counts for {col}:\")\n",
    "    print(raw_df[col].value_counts(dropna=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccccdabb",
   "metadata": {},
   "source": [
    "## 5. Handle Missing Values\n",
    "Remove or fill missing values to ensure the dataset is complete and reliable for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac472908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up missing data\n",
    "# Decide how to handle missing values: drop rows or fill them\n",
    "# Here, we drop rows with any missing values for simplicity\n",
    "clean_df = raw_df.dropna()  # Remove rows with any missing values\n",
    "# If you want to fill missing values instead, you could use:\n",
    "# clean_df = raw_df.fillna({'ColumnName': value, ...})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb24031",
   "metadata": {},
   "source": [
    "## 6. Remove Duplicates\n",
    "Drop duplicate rows to ensure each record in the dataset is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "726752ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any repeated records\n",
    "clean_df = clean_df.drop_duplicates()  # Drop duplicate rows to ensure each record is unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbdf421",
   "metadata": {},
   "source": [
    "## 7. Standardize Column Names\n",
    "Rename columns to a consistent format (lowercase, underscores) for easier handling and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44812821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column names uniform\n",
    "clean_df.columns = [col.strip().lower().replace(' ', '_') for col in clean_df.columns]  # Lowercase, remove spaces, use underscores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a2df04",
   "metadata": {},
   "source": [
    "## 7.1 Data Type Conversion\n",
    "Verify and correct the data types of all columns as required:\n",
    "- Convert InvoiceDate to datetime64[ns] for time-based analysis.\n",
    "- Convert CustomerID to integer after removing missing values.\n",
    "- Ensure StockCode is treated as a string/object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a69c0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvoiceDate type: datetime64[ns]\n",
      "CustomerID type: int64\n",
      "StockCode type: object\n"
     ]
    }
   ],
   "source": [
    "# Convert InvoiceDate to datetime64[ns]\n",
    "clean_df['invoicedate'] = pd.to_datetime(clean_df['invoicedate'])  # Convert InvoiceDate to datetime\n",
    "print('InvoiceDate type:', clean_df['invoicedate'].dtype)\n",
    "\n",
    "# Convert CustomerID to integer (after missing values removed)\n",
    "if 'customer_id' in clean_df.columns:\n",
    "    clean_df['customer_id'] = clean_df['customer_id'].astype(int)\n",
    "    print('CustomerID type:', clean_df['customer_id'].dtype)\n",
    "else:\n",
    "    print('CustomerID column not found!')\n",
    "\n",
    "# Ensure StockCode is treated as string/object\n",
    "if 'stockcode' in clean_df.columns:\n",
    "    clean_df['stockcode'] = clean_df['stockcode'].astype(str)  # Convert StockCode to string\n",
    "    print('StockCode type:', clean_df['stockcode'].dtype)\n",
    "elif 'StockCode' in clean_df.columns:\n",
    "    clean_df['StockCode'] = clean_df['StockCode'].astype(str)\n",
    "    print('StockCode type:', clean_df['StockCode'].dtype)\n",
    "else:\n",
    "    print('StockCode column not found!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bb6d28",
   "metadata": {},
   "source": [
    "## 8. Save Cleaned Data to CSV\n",
    "Export the cleaned DataFrame to a new CSV file in the 'cleaned' folder for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d71b39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of rows: 1067371\n",
      "Rows after removing missing values: 824364 (Removed: 243007)\n",
      "Rows after removing duplicates: 797885 (Removed: 26479)\n",
      "Total rows removed: 269486\n",
      "Final number of rows: 797885\n",
      "Final number of columns: 8\n"
     ]
    }
   ],
   "source": [
    "# Show summary of data cleaning results\n",
    "initial_rows = raw_df.shape[0]\n",
    "after_missing_rows = raw_df.dropna().shape[0]\n",
    "after_duplicates_rows = clean_df.shape[0]\n",
    "removed_missing = initial_rows - after_missing_rows\n",
    "removed_duplicates = after_missing_rows - after_duplicates_rows\n",
    "total_removed = initial_rows - after_duplicates_rows\n",
    "print(f\"Initial number of rows: {initial_rows}\")\n",
    "print(f\"Rows after removing missing values: {after_missing_rows} (Removed: {removed_missing})\")\n",
    "print(f\"Rows after removing duplicates: {after_duplicates_rows} (Removed: {removed_duplicates})\")\n",
    "print(f\"Total rows removed: {total_removed}\")\n",
    "print(f\"Final number of rows: {after_duplicates_rows}\")\n",
    "print(f\"Final number of columns: {clean_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d54d1",
   "metadata": {},
   "source": [
    "## 9. Data Cleaning Summary\n",
    "This section provides a summary of how much data was removed and how much remains after cleaning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b65be52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to cleaned/online_retail_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Export the cleaned data\n",
    "clean_df.to_csv('cleaned/online_retail_cleaned.csv', index=False)  # Save cleaned data to a new CSV file\n",
    "print('Cleaned data saved to cleaned/online_retail_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
